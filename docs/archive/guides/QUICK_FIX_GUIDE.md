# Quick Fix Guide for Testing Blind Spots

## üö® Problem Diagnosis

Why your testing framework might fail to detect pipeline operational issues:

### 1. **Testing Existence vs. Functionality**
```python
# ‚ùå INCORRECT: Only checks if service is alive
assert response.status_code == 200

# ‚úÖ CORRECT: Verifies actual business logic
assert response.status_code == 200
assert len(pipelines) > 0
assert pipeline_last_run_was_successful()
assert data_was_recently_updated()
```

### 2. **Missing Scheduling Tests**
- ‚ùå No verification that schedules are created.
- ‚ùå No verification that schedules are active.
- ‚ùå No verification that schedules actually trigger execution.

### 3. **Silent Failure Issues**
```python
# Problematic pattern:
except Exception as e:
    logger.error(f"Failed: {e}")
    continue  # ‚ö†Ô∏è Swallow error, continue as if nothing happened
```

---

## ‚ö° Immediately Actionable Fixes

### Step 1: Run Enhanced Tests (5 minutes)

```bash
# Run schedule verification
pytest tests/integration/test_pipeline_scheduling.py -v

# Run data freshness checks
pytest tests/data/test_data_freshness_enhanced.py -v
```

**Expected Results**:
- ‚úÖ Tests Pass ‚Üí Pipelines are healthy and operational.
- ‚ùå Tests Fail ‚Üí Immediate pinpointing of the root cause.

### Step 2: Interpret Failures

The tests will explicitly identify the bottleneck:

```
‚ùå No news data in the last 2 hours!
   - Latest data timestamp: 2026-01-11 10:30:00
   - Current time: 2026-01-11 12:30:00
   - Total records in DB: 1523
   Possible Causes:
   1. news_ingestion_pipeline schedule not running
   2. RSS feeds are all failing/returning empty
   3. Pipeline errors are being handled silently
```

### Step 3: Fix Based on Message

#### Issue A: Schedule Missing or Disabled
```bash
# Re-sync Airflow DAGs
docker exec alphapulse-airflow-scheduler airflow dags reserialize
```

#### Issue B: Schedule Exists but Doesn't Trigger
Check Airflow UI (http://localhost:8080):
1. Go to DAGs page.
2. Ensure the DAG is unpaused (Toggle is ON).
3. Check "Next Run" column for expected time.

#### Issue C: Pipeline Fails during Execution
```bash
# View task logs
docker logs alphapulse-airflow-scheduler

# Manually trigger a test run
docker exec alphapulse-airflow-scheduler airflow dags trigger news_ingestion_pipeline
```

---

## üîß Solving Silent Failures

### Improve Ingestion Logic

**File**: `airflow/plugins/alphapulse_utils/news_fetcher.py`

**Before**:
```python
except Exception as e:
    logger.error(f"Error fetching {source['name']}: {e}")
    continue  # ‚ö†Ô∏è Silent failure
```

**After**:
```python
except Exception as e:
    logger.error(f"Error fetching {source['name']}: {e}")
    failed_sources.append(source['name'])
    continue

# Raise if critical threshold reached
if df.empty and len(failed_sources) == len(rss_sources):
    raise RuntimeError(f"‚ùå All news sources failed: {failed_sources}")
```

---

## üìã Success Criteria

After applying fixes, you should observe:

1. **All New Tests Pass**
   ```
   tests/integration/test_pipeline_scheduling.py ‚úÖ 5 passed
   tests/data/test_data_freshness_enhanced.py ‚úÖ 8 passed
   ```

2. **Continuous Data Updates**
   - ‚úÖ News articles < 30 mins old.
   - ‚úÖ Sentiment scores < 1 hour old.

3. **Active Scheduling**
   - ‚úÖ All core DAGs (Price, News, Train) are active and recurring correctly.

---

**Created**: 2026-01-11
**Priority**: üî¥ Emergency Fixes