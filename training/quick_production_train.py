#!/usr/bin/env python3
"""
å¿«é€Ÿç”Ÿç”¢æ¨¡å‹è¨“ç·´è…³æœ¬ - Docker å„ªåŒ–ç‰ˆ

åœ¨ Docker å®¹å™¨ä¸­å¿«é€Ÿè¿­ä»£è¨“ç·´ç”Ÿç”¢ç´šæ¨¡å‹ã€‚
å„ªåŒ–é…ç½®ï¼šæ¸›å°‘è¿­ä»£æ¬¡æ•¸ã€ä½¿ç”¨é«˜æ•ˆæ¨¡å‹ã€å¿«é€Ÿé©—è­‰ã€‚
"""

import json
import os
import sys
from datetime import datetime
from pathlib import Path

# Add project path for training container
sys.path.insert(0, "/app/src")

from alphapulse.ml.training.iterative_trainer import IterativeTrainer, TrainingConfig


def quick_production_training():
    """å¿«é€Ÿç”Ÿç”¢æ¨¡å‹è¨“ç·´"""

    print("=" * 80)
    print("ğŸš€ å¿«é€Ÿç”Ÿç”¢æ¨¡å‹è¨“ç·´ - Docker å„ªåŒ–ç‰ˆ")
    print("=" * 80)
    print(f"â° é–‹å§‹æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()

    # å„ªåŒ–é…ç½® - å¿«é€Ÿè¿­ä»£
    config = TrainingConfig(
        # æ•¸æ“šè¨­ç½®
        data_source="model_features",
        target_column="price_change_1d",
        min_samples_required=500,  # é™ä½æœ€å°æ¨£æœ¬è¦æ±‚ä»¥å¿«é€Ÿæ¸¬è©¦
        # è¨“ç·´è¨­ç½® - æ¸›å°‘è¿­ä»£æ¬¡æ•¸ä»¥åŠ å¿«é€Ÿåº¦
        n_iterations=6,  # å¾ 10 æ¸›å°‘åˆ° 6 (æœ€æœ‰æ•ˆçš„æ¨¡å‹)
        test_size=0.15,
        validation_size=0.15,
        # äº¤å‰é©—è­‰ - æ¸›å°‘æŠ˜æ•¸
        cv_splits=3,  # å¾ 5 æ¸›å°‘åˆ° 3 ä»¥åŠ å¿«é€Ÿåº¦
        # æ—©åœè¨­ç½®
        early_stopping_rounds=30,  # å¾ 50 æ¸›å°‘åˆ° 30
        early_stopping_patience=2,  # å¾ 3 æ¸›å°‘åˆ° 2
        # éæ“¬åˆæª¢æ¸¬é–¾å€¼ï¼ˆä¿æŒç›¸åŒï¼‰
        max_train_val_gap=0.15,
        max_val_test_gap=0.10,
        min_val_r2=0.05,  # é™ä½è¦æ±‚ä»¥å¿«é€Ÿé€šé
        # MLflow è¨­ç½®
        mlflow_uri=os.getenv("MLFLOW_TRACKING_URI", "http://mlflow:5000"),
        experiment_name="quick_production_training",
        # è¼¸å‡ºè¨­ç½®
        output_dir=os.getenv("MODEL_OUTPUT_DIR", "/app/models/saved"),
        save_all_iterations=False,  # åªä¿å­˜æœ€ä½³æ¨¡å‹
    )

    print("ğŸ“‹ è¨“ç·´é…ç½®:")
    print(f"  ç›®æ¨™: {config.target_column}")
    print(f"  è¿­ä»£æ¬¡æ•¸: {config.n_iterations}")
    print(f"  äº¤å‰é©—è­‰: {config.cv_splits} æŠ˜")
    print(f"  æ—©åœè€å¿ƒ: {config.early_stopping_patience}")
    print(f"  è¼¸å‡ºç›®éŒ„: {config.output_dir}")
    print()

    # å‰µå»ºè¨“ç·´å™¨
    print("ğŸ”§ åˆå§‹åŒ–è¨“ç·´å™¨...")
    trainer = IterativeTrainer(config)

    # é‹è¡Œè¨“ç·´
    print("\nğŸ¯ é–‹å§‹è¨“ç·´...")
    print("-" * 80)

    try:
        summary = trainer.run_iterative_training()

        print("\n" + "=" * 80)
        print("âœ… è¨“ç·´å®Œæˆï¼")
        print("=" * 80)

        # é¡¯ç¤ºçµæœ
        if summary.get("best_model"):
            best = summary["best_model"]
            print(f"\nğŸ† æœ€ä½³æ¨¡å‹: {best['name']}")
            print(f"   é©—è­‰ MAE: {best['val_mae']:.6f}")
            print(f"   æ¸¬è©¦ MAE: {best['test_mae']:.6f}")
            print(f"   æ¸¬è©¦ RÂ²: {best['test_r2']:.4f}")
            print(f"   åƒæ•¸: {json.dumps(best['hyperparameters'], indent=4)}")

        print(f"\nğŸ“Š çµ±è¨ˆ:")
        print(f"   ç¸½è¿­ä»£: {summary['total_iterations']}")
        print(f"   éæ“¬åˆæ¨¡å‹: {summary['overfit_count']}")
        print(f"   æœ€ä½³è¿­ä»£: {summary['best_iteration']}")

        print(f"\nğŸ’¾ æ¨¡å‹æ–‡ä»¶:")
        print(f"   {config.output_dir}/best_model.pkl")
        print(f"   {config.output_dir}/training_summary.json")

        print(f"\nğŸ“ˆ MLflow:")
        print(f"   å¯¦é©—: {config.experiment_name}")
        print(f"   è¨ªå•: {config.mlflow_uri}")

        print(f"\nâ° å®Œæˆæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("=" * 80)

        return summary

    except Exception as e:
        print(f"\nâŒ è¨“ç·´å¤±æ•—: {str(e)}")
        import traceback

        traceback.print_exc()
        return None


def validate_environment():
    """é©—è­‰ Docker ç’°å¢ƒ"""
    print("\nğŸ” é©—è­‰ç’°å¢ƒ...")

    issues = []

    # æª¢æŸ¥æ•¸æ“šåº«é€£æ¥
    try:
        from sqlalchemy import create_engine, text

        db_url = os.getenv(
            "DATABASE_URL", "postgresql://postgres:postgres@postgres:5432/alphapulse"
        )
        engine = create_engine(db_url)
        with engine.connect() as conn:
            result = conn.execute(text("SELECT COUNT(*) FROM model_features"))
            count = result.scalar()
            if count < 500:
                issues.append(f"âš ï¸  model_features åªæœ‰ {count} è¡Œ (å»ºè­° > 500)")
            else:
                print(f"  âœ… model_features: {count} è¡Œ")
    except Exception as e:
        issues.append(f"âŒ æ•¸æ“šåº«é€£æ¥å¤±æ•—: {str(e)}")

    # æª¢æŸ¥ MLflow
    try:
        import mlflow

        mlflow_uri = os.getenv("MLFLOW_TRACKING_URI", "http://mlflow:5000")
        mlflow.set_tracking_uri(mlflow_uri)
        print(f"  âœ… MLflow: {mlflow_uri}")
    except Exception as e:
        issues.append(f"âš ï¸  MLflow é€£æ¥å•é¡Œ: {str(e)}")

    # æª¢æŸ¥è¼¸å‡ºç›®éŒ„
    output_dir = Path(os.getenv("MODEL_OUTPUT_DIR", "/app/models/saved"))
    if not output_dir.exists():
        output_dir.mkdir(parents=True, exist_ok=True)
        print(f"  âœ… å‰µå»ºè¼¸å‡ºç›®éŒ„: {output_dir}")
    else:
        print(f"  âœ… è¼¸å‡ºç›®éŒ„: {output_dir}")

    if issues:
        print("\nâš ï¸  ç™¼ç¾å•é¡Œ:")
        for issue in issues:
            print(f"  {issue}")
        print("\nç¹¼çºŒè¨“ç·´å¯èƒ½æœƒé‡åˆ°éŒ¯èª¤...")
        return False
    else:
        print("\nâœ… ç’°å¢ƒé©—è­‰é€šé")
        return True


def main():
    """ä¸»å‡½æ•¸"""
    print("\n" + "=" * 80)
    print("ğŸ¯ AlphaPulse å¿«é€Ÿç”Ÿç”¢æ¨¡å‹è¨“ç·´")
    print("=" * 80)

    # é©—è­‰ç’°å¢ƒ
    if not validate_environment():
        response = input("\næ˜¯å¦ç¹¼çºŒè¨“ç·´? (y/N): ")
        if response.lower() != "y":
            print("âŒ è¨“ç·´å–æ¶ˆ")
            return 1

    # é‹è¡Œè¨“ç·´
    summary = quick_production_training()

    if summary and summary.get("best_model"):
        print("\nâœ… æˆåŠŸï¼æ¨¡å‹å·²æº–å‚™å¥½ç”¨æ–¼ç”Ÿç”¢ã€‚")
        return 0
    else:
        print("\nâŒ è¨“ç·´æœªèƒ½ç”¢ç”Ÿæœ‰æ•ˆæ¨¡å‹ã€‚")
        return 1


if __name__ == "__main__":
    sys.exit(main())
